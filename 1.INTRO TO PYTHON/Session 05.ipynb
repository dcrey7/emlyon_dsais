{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"float:left\">\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"images/emlyon.png\" style=\"height:60px; float:left; padding-right:10px; margin-top:5px\" />\n",
    "        </td>\n",
    "        <td style=\"padding-bottom:10px;\">\n",
    "            <h1 style=\"border-bottom: 1px solid #eeeeee;\"> AI Booster Week 01 - Python for Data Science </h1>\n",
    "            <span style=\"display:inline-block; margin-top:-15px;\">\n",
    "            <a href=\"https://masters.em-lyon.com/fr/msc-in-data-science-artificial-intelligence-strategy\">[Emlyon]</a> MSc in Data Science & Artificial Intelligence Strategy (DSAIS)    \n",
    "            <br/>\n",
    "            Sep 2024, Paris | © Saeed VARASTEH\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Library II\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Options\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option(\"display.max_rows\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color:gray; font-size:16pt;'> \n",
    "Loading Data into Pandas\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/adult.csv', na_values=\"?\")\n",
    "print( data.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color:gray; font-size:16pt;'> \n",
    "Data Cleaning\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Drop Columns__\n",
    "\n",
    "Let's start by dropping columns, which we won't be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[\"fnlwgt\",\"education\",\"relationship\",\"capital-loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( data.shape )\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dealing with NaNs:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( data.shape )\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Rename Columns__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={\n",
    "        'capital-gain': 'capital', \n",
    "        'hours-per-week': 'workinghours'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Type Conversion__\n",
    "\n",
    "Notice anything off with the data types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets fix column type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['workclass'] = data.workclass.astype('category')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Creating New Column__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['above_mean_hours'] = data.workinghours > data.workinghours.mean()\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `assign` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.assign(above_mean_hours=lambda x: x.workinghours > x.workinghours.mean())\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\"> \n",
    "    <b>lambda</b> functions: These small, anonymous functions can receive multiple arguments, but can only contain one expression (the return value).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data['native-country'] == 'United-States') & (data['age'] >=30) & (data['age'] <= 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[~data['marital-status'].str.contains('married|Married')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'Female' category of 'gender' to 'F' ----- Inplace\n",
    "data.loc[ data['gender'] == 'Female','gender' ] = 'F'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[ data['gender'] == 'Male','gender' ] = 'M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(['age','educational-num'],ascending=[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Encodings__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__sklearn__ `LabelEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "race_encoder = LabelEncoder()\n",
    "data['race'] = race_encoder.fit_transform( data['race'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( {k: v for k, v in enumerate(list(race_encoder.classes_))} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__pandas__ One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoder = pd.get_dummies(data, columns=[\"race\"])\n",
    "print( data_encoder.shape )\n",
    "data_encoder.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discretization\n",
    "\n",
    "Use the `pd.cut()` function to create values bins of equal width:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(data[\"educational-num\"], bins=3, labels=['low', 'medium', 'high'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color:gray; font-size:16pt;'> \n",
    "Data Exploration\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count total data per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"native-country\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"native-country\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(\"native-country\").count()['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['count'] = 1\n",
    "data.groupby(\"native-country\").count()['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highest capital per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('native-country')['native-country','capital'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivot Table\n",
    "\n",
    "A pivot table is a table of grouped values that aggregates the individual items of a more extensive table within one or more discrete categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build a pivot table to compare educational-num across the gender in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.pivot_table(index='educational-num', columns='gender', values='count', aggfunc='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crosstabs\n",
    "\n",
    "The `pd.crosstab()` function provides an easy way to create a frequency table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=data[\"educational-num\"],columns=data[\"gender\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color:gray; font-size:16pt;'> \n",
    "Data Visualization\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will learn how to visualize data using pandas along with the Matplotlib and Seaborn libraries for additional features. We will create a variety of visualizations that will help us better understand our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before everthing, to embed SVG-format plots in the notebook, we will also call the `%config` and `%matplotlib inline` magics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting with Pandas\n",
    "\n",
    "We can create a variety of visualizations using the `plot()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Line Plot__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "The plot() method returns an Axes object that can be modified further (e.g., to add reference lines, annotations, labels, etc.).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[0:10,\"age\"].plot(title='Ages 0:10', ylabel='Age', alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bar Plot__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our next example, we will plot vertical bars to compare income throughput versus marital status. Let's start by creating a pivot table with the information we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = data.pivot_table(index='marital-status', columns='income', values='count', aggfunc='sum')\n",
    "plot_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas offers other plot types via the `kind` parameter, so we specify `kind='bar`' when calling the `plot()` method. Then, we further format the visualization using the `Axes` object returned by the `plot()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_data.plot(\n",
    "    kind='bar', rot=0, xlabel='', ylabel='adults', fontsize=8,\n",
    "    figsize=(12, 1.5), title='Income by Marital Status'\n",
    ")\n",
    "\n",
    "# customize the legend\n",
    "ax.legend(title='', loc='center', bbox_to_anchor=(0.5, -0.3), ncol=3, frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Plotting distributions__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compare the distribution of age across income levels. We will create two subplots for each income level with both a histogram and a kernel density estimate (KDE) of the distribution. \n",
    "\n",
    "Pandas has generated the `Figure` and `Axes` objects for both examples so far, but we can build custom layouts by creating them ourselves with Matplotlib using the `plt.subplots()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While pandas lets us specify that we want subplots and their layout (with the `subplots` and `layout` parameters, respectively), using Matplotlib to create the subplots directly gives us additional flexibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(6, 4))\n",
    "\n",
    "for income, ax in zip(data.income.unique(), axes):\n",
    "    plot_data = data[ data['income'] == income ].age\n",
    "    plot_data.plot(kind='hist', legend=False, density=True, alpha=0.8, ax=ax)\n",
    "    plot_data.plot(kind='kde', legend=False, color='blue', ax=ax)\n",
    "    ax.set(title=f'{income} Age Distributions', xlabel='Age')\n",
    "\n",
    "fig.tight_layout() # handle overlaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're new to the `zip()` function, check out [this article](https://realpython.com/python-zip-function/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Plotting with Seaborn__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __Seaborn__ library provides the means to easily visualize long-format data without first pivoting it. In addition, it also offers some additional plot types – once again building on top of Mtplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Seaborn, we can specify plot colors according to values of a column with the `hue` parameter. When working with functions that generate subplots, we can also specify how to split the subplots by values of a long-format column with the `col` and `row` parameters. Lets revisit the above plot using seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot( data=data, x='age', col='income', kde=True, height=2.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(3, 2))\n",
    "sns.distplot(data[\"age\"], ax=ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Heatmaps__\n",
    "\n",
    "We can also use Seaborn to visualize pivot tables as heatmaps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = data.pivot_table(index='marital-status', columns='income', values='count', aggfunc='sum')\n",
    "plot_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(data=plot_data, cmap='Blues', annot=True, fmt='.1f')\n",
    "_ = ax.set_title('Income by Marital Status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Box Plot__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(4, 4))\n",
    "sns.boxplot(y=\"age\", data=data, ax=ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Correlation Plot__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.heatmap(data.corr().abs(),  annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\" style=\"border-bottom: solid 1px lightgray; background-color:#f0ffff;\">\n",
    "    <img src=\"images/self.png\" style=\"height:60px; float:left; padding-right:10px;\" />\n",
    "    <span style=\"font-weight:bold; color:#1a8a8a\">\n",
    "        <h4 style=\"padding-top:25px;\"> SELF-STUDY </h4>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Test Objects\n",
    "\n",
    "| Operator | Description |\n",
    "|:---- |:---- |\n",
    "| **`pd.DataFrame(np.random.rand(20,5))`** | **5 columns and 20 rows of random floats** | \n",
    "| **`pd.Series(my_list)`** | **Create a series from an iterable my_list** | \n",
    "| **`df.index = pd.date_range('1900/1/30', periods=df.shape[0])`** | **Add a date index** | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Viewing/Inspecting Data\n",
    "\n",
    "| Operator | Description |\n",
    "|:---- |:---- |\n",
    "| **`df.head(n)`** | **First n rows of the DataFrame** | \n",
    "| **`df.tail(n)`** | **Last n rows of the DataFrame** | \n",
    "| **`df.shape`** | **Number of rows and columns** | \n",
    "| **`df.info()`** | **Index, Datatype and Memory information** | \n",
    "| **`df.describe()`** | **Summary statistics for numerical columns** | \n",
    "| **`s.value_counts(dropna=False)`** | **View unique values and counts** | \n",
    "| **`df.apply(pd.Series.value_counts)`** | **Unique values and counts for all columns** | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection\n",
    "\n",
    "| Operator | Description |\n",
    "|:---- |:---- |\n",
    "| **`df[col]`** | **Returns column with label col as Series** | \n",
    "| **`df[[col1, col2]]`** | **Returns columns as a new DataFrame** | \n",
    "| **`s.iloc[0]`** | **Selection by position** | \n",
    "| **`s.loc['index_one']`** | **Selection by index** | \n",
    "| **`df.iloc[0,:]`** | **First row** | \n",
    "| **`df.iloc[0,0]`** | **First element of first column** | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "| Operator | Description |\n",
    "|:---- |:---- |\n",
    "| **`df.columns = ['a','b','c']`** | **Rename columns** | \n",
    "| **`pd.isnull()`** | **Checks for null Values, Returns Boolean Arrray** | \n",
    "| **`pd.notnull()`** | **Opposite of pd.isnull()** | \n",
    "| **`df.dropna()`** | **Drop all rows that contain null values** | \n",
    "| **`df.dropna(axis=1)`** | **Drop all columns that contain null values** | \n",
    "| **`df.dropna(axis=1,thresh=n)`** | **Drop all rows have have less than n non null values** | \n",
    "| **`df.fillna(x)`** | **Replace all null values with x** | \n",
    "| **`s.fillna(s.mean())`** | **Replace all null values with the mean** | \n",
    "| **`s.astype(float)`** | **Convert the datatype of the series to float** | \n",
    "| **`s.replace(1,'one')`** | **Replace all values equal to 1 with 'one'** | \n",
    "| **`s.replace([2,3],['two', 'three'])`** | **Replace all 2 with 'two' and 3 with 'three'** | \n",
    "| **`df.rename(columns=lambda x: x + 1)`** | **Mass renaming of columns** | \n",
    "| **`df.rename(columns={'old_name': 'new_ name'})`** | **Selective renaming** | \n",
    "| **`df.set_index('column_one')`** | **Change the index** | \n",
    "| **`df.rename(index=lambda x: x + 1)`** | **Mass renaming of index** | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter, Sort, and Groupby\n",
    "\n",
    "| Operator | Description |\n",
    "|:---- |:---- |\n",
    "| **`df[df[col] > 0.6]`** | **Rows where the column col is greater than 0.6** | \n",
    "| **`df[(df[col] > 0.6) & (df[col] < 0.8)]`** | **Rows where 0.8 > col > 0.6** | \n",
    "| **`df.sort_values(col1)`** | **Sort values by col1 in ascending order** | \n",
    "| **`df.sort_values(col2,ascending=False)`** | **Sort values by col2 in descending order.5** | \n",
    "| **`df.sort_values([col1,col2],ascending=[True,False])`** | **Sort values by col1 in ascending order then col2 in descending order** | \n",
    "| **`df.groupby(col)`** | **Returns a groupby object for values from one column** | \n",
    "| **`df.groupby([col1,col2])`** | **Returns groupby object for values from multiple columns** | \n",
    "| **`df.groupby(col1)[col2]`** | **Returns the mean of the values in col2, grouped by the values in col1** | \n",
    "| **`df.pivot_table(index=col1,values=[col2,col3],aggfunc=mean)`** | **Create a pivot table that groups by col1 and calculates the mean of col2 and col3** | \n",
    "| **`df.groupby(col1).agg(np.mean)`** | **Find the average across all columns for every unique col1 group** | \n",
    "| **`df.apply(np.mean)`** | **Apply the function np.mean() across each column** | \n",
    "| **`nf.apply(np.max,axis=1)`** | **Apply the function np.max() across each row** | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join/Combine\n",
    "\n",
    "| Operator | Description |\n",
    "|:---- |:---- |\n",
    "| **`df1.append(df2)`** | **Add the rows in df1 to the end of df2 (columns should be identical)** | \n",
    "| **`pd.concat([df1, df2],axis=1)`** | **Add the columns in df1 to the end of df2 (rows should be identical)** | \n",
    "| **`df1.join(df2,on=col1, how='inner')`** | **SQL-style join the columns in df1 with the columns on df2 where the rows for col have identical values. The 'how' can be 'left', 'right', 'outer' or 'inner'** | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics\n",
    "\n",
    "| Operator | Description |\n",
    "|:---- |:---- |\n",
    "| **`df.describe()`** | **Summary statistics for numerical columns** | \n",
    "| **`df.mean()`** | **Returns the mean of all columns** | \n",
    "| **`df.corr()`** | **Returns the correlation between columns in a DataFrame** | \n",
    "| **`df.count()`** | **Returns the number of non-null values in each DataFrame column** | \n",
    "| **`df.max()`** | **Returns the highest value in each column** | \n",
    "| **`df.min()`** | **Returns the lowest value in each column** | \n",
    "| **`df.median()`** | **Returns the median of each column** | \n",
    "| **`df.std()`** | **Returns the standard deviation of each column** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data\n",
    "\n",
    "| Operator | Description |\n",
    "|:---- |:---- |\n",
    "| **`pd.read_csv(filename)`** | **From a CSV file** | \n",
    "| **`pd.read_table(filename)`** | **From a delimited text file (like TSV)** | \n",
    "| **`pd.read_excel(filename)`** | **From an Excel file** | \n",
    "| **`pd.read_sql(query, connection_object)`** | **Read from a SQL table/database** | \n",
    "| **`pd.read_json(json_string)`** | **Read from a JSON formatted string, URL or file.** | \n",
    "| **`pd.read_html(url)`** | **Parses an html URL, string or file and extracts tables to a list of dataframes** | \n",
    "| **`pd.read_clipboard()`** | **Takes the contents of your clipboard and passes it to read_table()** | \n",
    "| **`pd.DataFrame(dict)`** | **From a dict, keys for columns names, values for data as lists** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Data\n",
    "\n",
    "| Operator | Description |\n",
    "|:---- |:---- |\n",
    "| **`df.to_csv(filename)`** | **Write to a CSV file** | \n",
    "| **`df.to_excel(filename)`** | **Write to an Excel file** | \n",
    "| **`df.to_sql(table_name, connection_object)`** | **Write to a SQL table** | \n",
    "| **`df.to_json(filename)`** | **Write to a file in JSON format** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
