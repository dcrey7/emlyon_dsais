{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb8e8ec-eedc-4793-a1f6-ddb545de5fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(\"header.md\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2036fa-b3da-45ac-9057-08798041099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "# Ignore warnings from seaborn\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pprint import pprint\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0067a6-ec74-46ae-b53d-f924f93984d4",
   "metadata": {},
   "source": [
    "## Session 04 - Hypothesis testing - Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ec64bc-f03b-419a-9eac-c3055d374ee9",
   "metadata": {},
   "source": [
    "## Normal distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384fa60f-b98a-455d-b987-c0775bdfc33d",
   "metadata": {},
   "source": [
    "### [easy] Estimate normality of data\n",
    "\n",
    "Write a function that will analyze data to evaluate if it is coming from a normal distribution:\n",
    " - compute mean/median/mode => are they close?\n",
    " - is IQR close to $1.33\\sigma$?\n",
    " - is range close to $6\\sigma$?\n",
    "\n",
    "Use plot from this morning (histogram vs. normal distribution)!\n",
    "\n",
    "Test on randomly generated data (using `np.random` module) data and `weights_heights` data.\n",
    "\n",
    "Test your function on the `weights_heights.csv` and `salary.csv` (salary) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275e7b02-f138-447f-bdfe-dad536fa166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "\n",
    "def msds_test_normality(data):\n",
    "    pass\n",
    "\n",
    "\n",
    "def test_msds_test_normality():\n",
    "    wh = pd.read_csv(\"data/heights_weights.csv\")\n",
    "    msds_test_normality(wh[\"Weight(Pounds)\"])\n",
    "    norm_data = np.random.normal(size=1000)\n",
    "    msds_test_normality(norm_data)\n",
    "\n",
    "\n",
    "test_msds_test_normality()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61256862-1ff1-407d-860b-b13ccecd30c6",
   "metadata": {},
   "source": [
    "### [moderate] Fit a normal distribution on heights and weights\n",
    "\n",
    "Fit a Normal distribution (find best $\\mu$ and $\\sigma^2$ values) for weights and heights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955fa540-2623-440a-b95c-81b1afdc2894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "def msds_fit_normal(data):\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def test_msds_fit_normal():\n",
    "    wh = pd.read_csv(\"data/heights_weights.csv\")\n",
    "    msds_fit_normal(wh[\"Weight(Pounds)\"])\n",
    "\n",
    "\n",
    "test_msds_fit_normal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b204418c-8b2f-46a4-a4f4-5150db28f0df",
   "metadata": {},
   "source": [
    "## Hypothesis testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63e3dcf-5b2f-4c53-a64c-dcb4f2fd299f",
   "metadata": {},
   "source": [
    "### [moderate] test the relationship between 2 variables\n",
    "\n",
    "Write a function that will compute an independence $\\chi^2$ test between two categorical variables.\n",
    "\n",
    "It should output details about the test and the final decision.\n",
    "\n",
    "Test on `salary.csv` dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dba7531-de23-40a7-bd99-e59c31839d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2, chi2_contingency\n",
    "\n",
    "\n",
    "def chi2_independance_stat_ct(cont_table):\n",
    "    pass\n",
    "\n",
    "\n",
    "def msds_chi2_independance_test(X, Y, alpha):\n",
    "    \"\"\"\n",
    "    CHI2 independance test for categorical variables\n",
    "    \"\"\"\n",
    "    cont_table = pd.crosstab(X, Y)\n",
    "\n",
    "    df = (cont_table.shape[0] - 1) * (cont_table.shape[1] - 1)\n",
    "    x2 = chi2_independance_stat_ct(cont_table)\n",
    "    critical_value = chi2.ppf(1 - alpha, df=df)\n",
    "    pvalue = 1 - chi2.cdf(x2, df=df)\n",
    "    if abs(x2) > critical_value:\n",
    "        print(\n",
    "            f\"Reject Ho (variables are NOT likely independant)!\\n X2={x2:.04f} C={critical_value:.04f} alpha={alpha:.04f} p-value={pvalue:.04f}\"\n",
    "        )\n",
    "        return False\n",
    "    else:\n",
    "        print(\n",
    "            f\"Cannot reject Ho (variables are likely independant)!\\n X2={x2:.04f} C={critical_value:.04f} alpha={alpha:.04f} p-value={pvalue:.04f}\"\n",
    "        )\n",
    "        return True\n",
    "\n",
    "\n",
    "def test_msds_chi2_independance_test():\n",
    "    salary = pd.read_csv(\"data/salary.csv\")\n",
    "    salary = salary.dropna()\n",
    "    X = salary.Gender\n",
    "    Y = salary[\"Education Level\"]\n",
    "    assert msds_chi2_independance_test(X, Y, 0.05) == True\n",
    "    print(chi2_contingency(pd.crosstab(X, Y), correction=False))\n",
    "\n",
    "\n",
    "test_msds_chi2_independance_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fc619c-eead-4447-a98c-7c67aa8b5ea2",
   "metadata": {},
   "source": [
    "### [advanced] $\\chi^2$ test for normality\n",
    "\n",
    "A normality $X^2$ test can be performed to check if the distribution of a given variable follows a Normal distribution (it is likely that this histogram comes from a Normal distribution?).\n",
    "\n",
    "To do that we will compute the empirical histograms with a given number of bins $n$ (done in session 02) and we will compute the  between the sum of squared differences between expected and computed frequencies.\n",
    "\n",
    "Here is the full procedure:\n",
    " - estimate mean and standard deviation \n",
    " - compute an histogram (relative frequencies) with $n$ bins (test with 15 for instance) => store in list called $H$\n",
    " - compute the expected relative frequencies if histogram was actually coming from a Normal distribution with 0 mean and unit variance. Store in a list called $N$\n",
    " - compute the test statistic:\n",
    "\n",
    "$\\Large \\displaystyle{X^2 = \\sum_{i=1}^{n} \\frac{(H_i - N_i)^2}{N_i}}$\n",
    "\n",
    " - This $X^2$ statistics will follow a $\\chi^2$ distribution with $n-1$ degrees of freedom (since mean and variance are known)\n",
    " - Set a significance level $\\alpha$ (say $0.05$) and compute associated critical value\n",
    " - Conclude your test and give the $p$-value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada161f-ace6-4da9-857c-b4b95820fc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "\n",
    "def msds_normality_chi2_test(data, alpha=0.05, nbins=20):\n",
    "    pass\n",
    "\n",
    "\n",
    "def test_msds_normality_chi2_test():\n",
    "    wh = pd.read_csv(\"data/heights_weights.csv\")\n",
    "    msds_normality_chi2_test(wh[\"Weight(Pounds)\"], nbins=15)\n",
    "    uni_data = np.random.uniform(size=1000)\n",
    "    msds_normality_chi2_test(uni_data, nbins=10)\n",
    "\n",
    "\n",
    "test_msds_normality_chi2_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24b23f4-cf59-4a0a-a87e-b27ec1da5e33",
   "metadata": {},
   "source": [
    "## Confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555d986a-7855-49d1-8767-ae4481bb9e7f",
   "metadata": {},
   "source": [
    "### [easy] Sample mean confidence intervals\n",
    "\n",
    "The standard error:\n",
    "\n",
    "$\\Large {\\displaystyle \\frac{\\bar{x}-\\mu}{s\\sqrt{n}} } $\n",
    "\n",
    "can also be used to build confidence intervals.\n",
    "When population variance is not known, it will follow a Student T distribution with $(n-1)$ degrees of freedom.\n",
    "\n",
    "So if we set a significance level $\\alpha$, we can build the following confidence interval:\n",
    "\n",
    "$\\Large {\\displaystyle \\left[{\\bar {x}}-{\\frac {cs}{\\sqrt {n}}},{\\bar {x}}+{\\frac {cs}{\\sqrt {n}}}\\right]} $ \n",
    "\n",
    "$c$ being the critical value for the T distribution, so the value $c$ such that $P(-c <= T <= c) = 1-\\alpha$.\n",
    "\n",
    "Write a function that will, given a dataset and a significance level, compute the sample mean and give associated confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d79c8-e140-4928-afef-fcb306c73ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "\n",
    "def msds_sample_mean_ci(data, alpha):\n",
    "    pass\n",
    "\n",
    "\n",
    "def test_msds_sample_mean_ci():\n",
    "    test_data = [1, 1, 2, 2, 1, 2, 1, 1, 1, 2]\n",
    "    result = msds_sample_mean_ci(test_data, 0.05)\n",
    "    assert abs(result[0] - 1.100653911606782) < 1e-5\n",
    "\n",
    "\n",
    "test_msds_sample_mean_ci()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02abcf8-c082-4a28-bebc-0344ac0dd079",
   "metadata": {},
   "source": [
    "### [advanced] Bootstrap confidence interval\n",
    "\n",
    "The computation of confidence interval at previous stage makes quite strong asumption on the discution of $\\bar{x}$.\n",
    "In order to build confidence interval without having to make such asumption, on can use the **bootstrap** method!\n",
    "\n",
    "The idea behind boostrap is to generate many samples using the data as the base material.\n",
    "It can be shown that if you take a random sample (sampling with replacement) from your original data (with same size!), then you can use these samples to have an idea of the distribution of $\\bar{x}$ for instance.\n",
    "\n",
    "Using some datasets we already encountered (salary, weights and heights), compute confidence interval using the boostrap method and compare your results with the ones from the previous question.\n",
    "\n",
    "The procedure for boostrap confidence interval is the following:\n",
    " - pick a number of samples you will generate (say 1000)\n",
    " - generate these samples (with replacement) from your original data, and compute for each of them the sample mean\n",
    " - plot the (empirical) distribution (histogram) of these 1000 sample means\n",
    " - from the distribution, compute the critical values $c_l$ and $c_u$\n",
    " - return confidence intervals:\n",
    "\n",
    "$\\Large {\\displaystyle \\left[2{\\bar {x}}-c_u,2{\\bar {x}}-c_l\\right]}$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d77916f-65f9-4d93-b1b0-5bca3b785184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def msds_bootstrap_ci(data, N=10000, alpha=0.05, pivot=True):\n",
    "    pass\n",
    "\n",
    "\n",
    "def test_msds_bootstrap_ci():\n",
    "    salary = pd.read_csv(\"data/salary.csv\")\n",
    "    salary = salary.dropna()\n",
    "    muh, muh_l, muh_h = msds_bootstrap_ci(salary.Age)\n",
    "    print(f\"Estimated Mean with CI : [{muh_l:.02f}, {muh:.02f}, {muh_h:.02f}]\")\n",
    "\n",
    "\n",
    "test_msds_bootstrap_ci()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01239e6-e4f0-44e2-964c-80e08eb74d14",
   "metadata": {},
   "source": [
    "## Object-oriented programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d241a5-2510-462d-b726-eb200c1821c4",
   "metadata": {},
   "source": [
    "### [advanced] Convert all your functions and organize them in classes using OOP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
