{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ea3ef9-cf04-469a-b2b0-9dd538f6698d",
   "metadata": {},
   "source": [
    "# Week3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c82b922-88f2-4446-ac21-a842791e6966",
   "metadata": {},
   "source": [
    "## 01/10/2024 Tuesday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eebea1-7180-4c49-911f-42fdaaab1210",
   "metadata": {},
   "source": [
    "- ML is still a black box\n",
    "- XAI - explainable ai\n",
    "- model is model and cannot represent reality , always some error Y=f(x)+ E\n",
    "- PASSIMONIOUS - OCCAMS RAZOR - minimunm predictors, maximum prediction\n",
    "- Linear model are bad models and never get close to the actual Y but close these are parameteric models, not overfitting\n",
    "- KNN models are good models are get very close to actual Y, not parameteric model , there is overfitting\n",
    "- observations/data points in the features/columns are measured in distance between them, but features/ columns are used to measured by the angle between them because they are vectors\n",
    "- variable centered approach\n",
    "    - In a credit risk model, you might use a variable-centered approach to study how different financial behaviors (e.g., income, credit utilization, payment history) are related to credit scores.\n",
    "- person centered approach\n",
    "    - In customer segmentation, a person-centered approach might group customers into distinct clusters based on their purchasing behaviors, demographics, or preferences, allowing for personalized marketing strategies.\n",
    "- MSE is mean squared error and MAE is mean absoulute error. MSE >= MAE always"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b3ca92-d20c-4666-a096-cc0315ba2ab1",
   "metadata": {},
   "source": [
    "## 02/10/2024 Thursday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a611e915-e94a-48c1-9c31-2249af04d04c",
   "metadata": {},
   "source": [
    "- statistical learning\n",
    "    - statistical learning is for sample can be small \n",
    "    - confidence is absed on assumptoions made on the distribution of the error\n",
    "- machine learning\n",
    "    -  ML is for sample can be large\n",
    "    -  ML confidence is based on multiple resampling\n",
    "  - linear regression\n",
    "      - y = Bo+B1X1+B2X2....\n",
    "      - Betas (Bo, B1, B2....Bn) is linear, basically degree of B1 should be 1\n",
    "      - x can be anything , it can be square, log, sqrt or any transformation.\n",
    "      - minimizing the loss function which is residual sum if sq\n",
    "      - convex function has only 1 local minima\n",
    "      - objective fucntion minimize has many local minima\n",
    "      - metrics\n",
    "        - RMSE is same unit in LR, MSE is squared\n",
    "        - R^2 adj (penalizes the variables with not adjusted) and R^2 which\n",
    "    - when xj increases by 1 unit y increases by Bj unit. ex - B tv\n",
    "    - standard beta Bi = Sx/Sy*Bj to compare different unit (standardizing all variables)\n",
    "   \n",
    "    - after i see non linear correaltion in pairplot , i will make correlation heatmap with kk\n",
    "    - Hintss\n",
    "        - if i raw data and do linear regression , i get Bo and then all coefficients, to get the important feature i have to standardize it standard coefficient and highest one is the most important. the standard coeffiecnt and coeffient are different\n",
    "        - If i standardize the data and ,my Bo becomes 0 because all my mean is 0, i will get coeffiencet which are already standardized, both my standard coeffienct and coefficient is the same\n",
    "         - if tv is increased by 1 std dev then the sales will increase by 0.75 std of sales ofr stdarized data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d95758a-7bd9-44f8-a97a-2b94ba491dbc",
   "metadata": {},
   "source": [
    "### 04/10/2024 Friday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2d842a-932b-467d-b156-10cea841cc3f",
   "metadata": {},
   "source": [
    "- log and logit\n",
    "- pi(x)/1-pi(x)=odds (winning)/ odd (losing)=P(Y-1|X=x)/P odd(x)\n",
    "- odds ratio is the exponent of coefficient\n",
    "- Bj is the increase in logit when Xj increases by 1 AND  When Xj is increased by 1 unit , the odds are multiplied exponenetial Bj\n",
    "- feature importance by standardizing the cofficient ,\n",
    "- output of logit has no units , its a probability\n",
    "- minimizing the loss function , minimizing function changes based on function\n",
    "- precision is TP / YES and Predicted , recall is TP/ YEs and Actual\n",
    "- Specificity = TN/ Yes and Actual = 1- FPR\n",
    "- F1 measure =  2*Precision*Recall/Presicion + Recall\n",
    "- the baseline in logistic classification is that when proportion of default yes / proportion of default no when all the predictors are 0.\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
